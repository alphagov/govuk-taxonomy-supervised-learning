{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical, layer_utils, plot_model\n",
    "\n",
    "from keras.layers import (Embedding, Input, Dense, Dropout, \n",
    "                          Activation, Conv1D, MaxPooling1D, Flatten, concatenate, Reshape)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.callbacks import TensorBoard, Callback, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n",
    "\n",
    "from scipy import sparse\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR=os.getenv('DATADIR')\n",
    "#DATADIR='/data' #this was put in for AWS run but doesn't work locally..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(DATADIR, 'train_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'meta', 'title', 'desc', 'y']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (161020, 1000)\n",
      "meta_train.shape = (161020, 452)\n",
      "title_train.shape = (161020, 10000)\n",
      "desc_train.shape = (161020, 10000)\n",
      "y_train.shape = (161020, 218)\n"
     ]
    }
   ],
   "source": [
    "x_train = sparse.csr_matrix(train['x'].all()).todense()\n",
    "meta_train = sparse.csr_matrix(train['meta'].all()).todense()\n",
    "title_train = sparse.csr_matrix(train['title'].all()).todense()\n",
    "desc_train = sparse.csr_matrix(train['desc'].all()).todense()\n",
    "y_train = sparse.csr_matrix(train['y'].all()).todense()\n",
    "\n",
    "print('x_train.shape = {}'.format(x_train.shape))\n",
    "print('meta_train.shape = {}'.format(meta_train.shape))\n",
    "print('title_train.shape = {}'.format(title_train.shape))\n",
    "print('desc_train.shape = {}'.format(desc_train.shape))\n",
    "print('y_train.shape = {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = np.load(os.path.join(DATADIR, 'dev_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dev.shape = (10377, 1000)\n",
      "meta_dev.shape = (10377, 452)\n",
      "title_dev.shape = (10377, 10000)\n",
      "desc_dev.shape = (10377, 10000)\n",
      "y_dev.shape = (10377, 218)\n"
     ]
    }
   ],
   "source": [
    "x_dev = sparse.csr_matrix(dev['x'].all()).todense()\n",
    "meta_dev = sparse.csr_matrix(dev['meta'].all()).todense()\n",
    "title_dev = sparse.csr_matrix(dev['title'].all()).todense()\n",
    "desc_dev = sparse.csr_matrix(dev['desc'].all()).todense()\n",
    "y_dev = sparse.csr_matrix(dev['y'].all()).todense()\n",
    "\n",
    "print('x_dev.shape = {}'.format(x_dev.shape))\n",
    "print('meta_dev.shape = {}'.format(meta_dev.shape))\n",
    "print('title_dev.shape = {}'.format(title_dev.shape))\n",
    "print('desc_dev.shape = {}'.format(desc_dev.shape))\n",
    "print('y_dev.shape = {}'.format(y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.load(os.path.join(DATADIR, 'test_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape = (10379, 1000)\n",
      "meta_test.shape = (10379, 452)\n",
      "title_test.shape = (10379, 10000)\n",
      "desc_test.shape = (10379, 10000)\n",
      "y_test.shape = (10379, 218)\n"
     ]
    }
   ],
   "source": [
    "x_test = sparse.csr_matrix(test['x'].all()).todense()\n",
    "meta_test = sparse.csr_matrix(test['meta'].all()).todense()\n",
    "title_test = sparse.csr_matrix(test['title'].all()).todense()\n",
    "desc_test = sparse.csr_matrix(test['desc'].all()).todense()\n",
    "y_test = sparse.csr_matrix(test['y'].all()).todense()\n",
    "\n",
    "print('x_test.shape = {}'.format(x_test.shape))\n",
    "print('meta_test.shape = {}'.format(meta_test.shape))\n",
    "print('title_test.shape = {}'.format(title_test.shape))\n",
    "print('desc_test.shape = {}'.format(desc_test.shape))\n",
    "print('y_test.shape = {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### previous shapes in old data \n",
    "Shape of x_train: (150870, 1000)\n",
    "Shape of metax_train: (150870, 436)\n",
    "Shape of titlex_train: (150870, 10000)\n",
    "Shape of descx_train: (150870, 10000)\n",
    "Shape of y_train: (150870, 210)\n",
    "\n",
    "Shape of x_dev: (9234, 1000)\n",
    "Shape of meta_dev: (9234, 436)\n",
    "Shape of titlex_dev: (9234, 10000)\n",
    "Shape of descx_dev: (9234, 10000)\n",
    "Shape of y_dev: (9234, 210)\n",
    "\n",
    "Shape of x_test: (9234, 1000)\n",
    "Shape of metax_test: (9234, 436)\n",
    "Shape of titlex_test: (9234, 10000)\n",
    "Shape of descx_test: (9234, 10000)\n",
    "Shape of y_test: (9234, 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_tokenizer_from_file(filename):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    with open(filename, 'r') as infile:\n",
    "        tokenizer_data = json.load(infile)\n",
    "\n",
    "    tokenizer.word_counts = OrderedDict(tokenizer_data['word_counts'])\n",
    "    tokenizer.word_docs = tokenizer_data['word_docs']\n",
    "    tokenizer.word_index = tokenizer_data['word_index']\n",
    "    tokenizer.document_count = tokenizer_data['document_count']\n",
    "    tokenizer.index_docs = tokenizer_data['index_docs']\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_combined_text = load_tokenizer_from_file(os.path.join(DATADIR, \"combined_text_tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(tokenizer_combined_text.word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00756\n",
      "8.01512\n"
     ]
    }
   ],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = meta_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(title_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(desc_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "wordindex (InputLayer)          (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    31285300    wordindex[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedded (Dropout)      (None, 1000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv1D)                  (None, 996, 128)     64128       dropout_embedded[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling1D)        (None, 199, 128)     0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout0 (Dropout)              (None, 199, 128)     0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 195, 128)     82048       dropout0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling1D)        (None, 39, 128)      0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "meta (InputLayer)               (None, 452)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles (InputLayer)             (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "descs (InputLayer)              (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, 35, 128)      82048       max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_meta (Dense)             (None, 128)          57984       meta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "hidden_title (Dense)            (None, 128)          1280128     titles[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_desc (Dense)             (None, 128)          1280128     descs[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (MaxPooling1D)  (None, 1, 128)       0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_meta (Dropout)          (None, 128)          0           hidden_meta[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_title (Dropout)         (None, 128)          0           hidden_title[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_desc (Dropout)          (None, 128)          0           hidden_desc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dropout_meta[0][0]               \n",
      "                                                                 dropout_title[0][0]              \n",
      "                                                                 dropout_desc[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected0 (Dense)        (None, 400)          205200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 400)          0           fully_connected0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected1 (Dense)        (None, 218)          87418       dropout1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 34,424,382\n",
      "Trainable params: 34,424,382\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 & 3. Train & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161020 samples, validate on 10377 samples\n",
      "Epoch 1/10\n",
      "161020/161020 [==============================] - 118s 733us/step - loss: 0.0092 - binary_accuracy: 0.9948 - f1: nan - val_loss: 0.0052 - val_binary_accuracy: 0.9965 - val_f1: 0.7182\n",
      "Epoch 2/10\n",
      "161020/161020 [==============================] - 109s 679us/step - loss: 0.0031 - binary_accuracy: 0.9980 - f1: 0.8722 - val_loss: 0.0048 - val_binary_accuracy: 0.9968 - val_f1: 0.7544\n",
      "Epoch 3/10\n",
      "161020/161020 [==============================] - 109s 678us/step - loss: 0.0023 - binary_accuracy: 0.9985 - f1: 0.9073 - val_loss: 0.0048 - val_binary_accuracy: 0.9970 - val_f1: 0.7645\n",
      "Epoch 4/10\n",
      "161020/161020 [==============================] - 109s 679us/step - loss: 0.0019 - binary_accuracy: 0.9988 - f1: 0.9237 - val_loss: 0.0048 - val_binary_accuracy: 0.9970 - val_f1: 0.7681\n"
     ]
    }
   ],
   "source": [
    "# metrics callback causes: CCCCCCR55555555511155\n",
    "# So disable for now\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# Replicates `model` on 8 GPUs.\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = parallel_model.fit(\n",
    "    {'meta': meta_train, 'titles': title_train, 'descs': desc_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([meta_dev, title_dev, desc_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'val_f1', 'loss', 'binary_accuracy', 'f1'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32b70e9e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, 5)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32b6f5da20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(epochs, f1_values, 'bo', label='Training f1')\n",
    "plt.plot(epochs, val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(array,name):\n",
    "    df = pd.DataFrame(data = array.tolist(),columns=[i for i in range(1,y_train.shape[1]+1)])\n",
    "    df.to_csv(os.path.join(DATADIR, name+'_results.csv.gz'),compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_1822_2802_'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_run = time.strftime(\"_%H%M_%d%m_\")\n",
    "date_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = parallel_model.predict([meta_train, title_train, desc_train, x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob,\"train\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.95955631751802206, 0.94534095765246939, 0.95239559628513437, None)\n",
      "macro: (0.97315445272210577, 0.97045367131346716, 0.97150078499329717, None)\n",
      "weightedmacro: (0.95934798196480209, 0.94534095765246939, 0.95187151534482117, None)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_dev = parallel_model.predict([meta_dev, title_dev, desc_dev, x_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob_dev,\"dev\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev = y_prob_dev.copy()\n",
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.80313736574335781, 0.73613989637305699, 0.76818058934847255, None)\n",
      "macro: (0.5713422971400316, 0.53813328748350231, 0.5373727005363258, None)\n",
      "weightedmacro: (0.80478679828302957, 0.73613989637305699, 0.76542912756357051, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedmacro: (array([ 0.        ,  0.77777778,  0.90082645,  0.46666667,  1.        ,\n",
      "        0.59615385,  0.16666667,  0.82236842,  0.        ,  0.875     ,\n",
      "        1.        ,  0.875     ,  0.        ,  0.        ,  0.42857143,\n",
      "        0.        ,  0.61904762,  0.        ,  0.        ,  0.75      ,\n",
      "        0.8402439 ,  0.75135135,  0.83076923,  0.        ,  0.5       ,\n",
      "        0.        ,  0.25      ,  1.        ,  1.        ,  0.66666667,\n",
      "        0.57142857,  0.61538462,  1.        ,  0.        ,  0.55172414,\n",
      "        0.80869565,  0.66666667,  0.65384615,  0.66343042,  0.5       ,\n",
      "        0.65277778,  0.        ,  0.68      ,  0.79896907,  0.        ,\n",
      "        0.        ,  0.46666667,  0.625     ,  0.        ,  0.75862069,\n",
      "        0.77857143,  1.        ,  0.66666667,  0.22222222,  1.        ,\n",
      "        0.33333333,  0.        ,  0.        ,  0.90972222,  0.25      ,\n",
      "        0.76296296,  0.5       ,  0.66666667,  0.72727273,  0.65517241,\n",
      "        0.        ,  0.77922078,  0.70754717,  0.        ,  0.98876404,\n",
      "        0.42857143,  1.        ,  1.        ,  0.66666667,  0.66071429,\n",
      "        0.72727273,  0.85714286,  0.82129278,  0.        ,  0.78947368,\n",
      "        1.        ,  0.41176471,  0.77777778,  0.87341772,  0.86413709,\n",
      "        0.        ,  0.        ,  0.76865672,  0.        ,  0.5       ,\n",
      "        1.        ,  1.        ,  0.        ,  0.8757764 ,  0.84146341,\n",
      "        0.86885246,  0.66666667,  1.        ,  0.33333333,  0.6       ,\n",
      "        0.38461538,  0.76666667,  0.94230769,  0.35      ,  0.        ,\n",
      "        0.65      ,  0.44444444,  0.69444444,  0.        ,  0.        ,\n",
      "        0.85714286,  1.        ,  0.57142857,  0.86666667,  0.3       ,\n",
      "        0.        ,  1.        ,  0.        ,  0.33333333,  0.71351351,\n",
      "        0.74358974,  0.68888889,  0.38095238,  0.72727273,  0.90909091,\n",
      "        0.94871795,  1.        ,  0.83516484,  0.        ,  0.94897959,\n",
      "        0.        ,  1.        ,  0.5       ,  0.        ,  1.        ,\n",
      "        0.80787037,  0.38461538,  0.82330097,  0.85436893,  0.        ,\n",
      "        1.        ,  0.        ,  1.        ,  0.5       ,  0.8358209 ,\n",
      "        0.84615385,  0.8       ,  0.75555556,  0.33333333,  1.        ,\n",
      "        0.        ,  0.        ,  0.90769231,  0.        ,  0.        ,\n",
      "        0.        ,  0.625     ,  0.93627451,  0.75510204,  0.9       ,\n",
      "        0.5       ,  0.5       ,  0.89795918,  0.84536082,  0.78947368,\n",
      "        0.73684211,  0.66666667,  0.61333333,  0.87570621,  0.80714286,\n",
      "        0.89411765,  1.        ,  0.        ,  0.16666667,  0.5       ,\n",
      "        0.671875  ,  0.66666667,  0.76190476,  1.        ,  0.33333333,\n",
      "        0.        ,  0.75      ,  0.9       ,  0.66666667,  0.8       ,\n",
      "        0.83333333,  0.92783505,  0.5       ,  0.5       ,  0.76678445,\n",
      "        1.        ,  0.        ,  0.76923077,  1.        ,  0.4       ,\n",
      "        0.5       ,  0.5       ,  0.7201087 ,  0.25      ,  0.67647059,\n",
      "        0.        ,  0.83333333,  0.73684211,  0.9       ,  0.        ,\n",
      "        0.        ,  0.93567251,  0.84615385,  0.625     ,  0.4       ,\n",
      "        0.875     ,  0.73113208,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.94827586]), array([ 0.        ,  0.875     ,  0.94782609,  0.5       ,  1.        ,\n",
      "        0.484375  ,  0.1       ,  0.67204301,  0.        ,  0.58333333,\n",
      "        0.66666667,  0.82352941,  0.        ,  0.        ,  0.58333333,\n",
      "        0.        ,  0.78787879,  0.        ,  0.        ,  0.86013986,\n",
      "        0.68831169,  0.68137255,  0.84816754,  0.        ,  0.33333333,\n",
      "        0.        ,  0.33333333,  1.        ,  1.        ,  0.66666667,\n",
      "        1.        ,  0.66666667,  0.4       ,  0.        ,  0.47058824,\n",
      "        0.77178423,  0.8       ,  0.70833333,  0.57746479,  0.5       ,\n",
      "        0.51648352,  0.        ,  0.56666667,  0.88068182,  0.        ,\n",
      "        0.        ,  0.38888889,  1.        ,  0.        ,  0.70967742,\n",
      "        0.81954887,  0.5       ,  0.5       ,  0.33333333,  0.5       ,\n",
      "        1.        ,  0.        ,  0.        ,  0.85620915,  0.375     ,\n",
      "        0.57222222,  0.66666667,  0.57142857,  0.88888889,  0.46341463,\n",
      "        0.        ,  0.47808765,  0.59055118,  0.        ,  0.92631579,\n",
      "        0.33333333,  1.        ,  0.6       ,  0.57142857,  0.58730159,\n",
      "        0.85714286,  0.80898876,  0.79120879,  0.        ,  0.85551331,\n",
      "        1.        ,  0.63636364,  0.77777778,  0.78857143,  0.79325843,\n",
      "        0.        ,  0.        ,  0.57541899,  0.        ,  0.25      ,\n",
      "        1.        ,  0.83333333,  0.        ,  0.77900552,  0.75824176,\n",
      "        0.62352941,  1.        ,  1.        ,  0.4       ,  0.8       ,\n",
      "        0.35714286,  0.76666667,  0.81666667,  0.5       ,  0.        ,\n",
      "        0.72222222,  0.66666667,  0.75757576,  0.        ,  0.        ,\n",
      "        0.6       ,  1.        ,  0.8       ,  0.92857143,  0.75      ,\n",
      "        0.        ,  0.33333333,  0.        ,  0.5       ,  0.63768116,\n",
      "        0.78378378,  0.67391304,  0.44444444,  0.66666667,  0.86419753,\n",
      "        0.888     ,  0.2       ,  0.57142857,  0.        ,  0.93      ,\n",
      "        0.        ,  0.5       ,  0.5       ,  0.        ,  1.        ,\n",
      "        0.78251121,  0.71428571,  0.83464567,  0.89795918,  0.        ,\n",
      "        0.28571429,  0.        ,  1.        ,  1.        ,  0.74666667,\n",
      "        0.6875    ,  0.68      ,  0.70833333,  1.        ,  0.83333333,\n",
      "        0.        ,  0.        ,  0.87084871,  0.        ,  0.        ,\n",
      "        0.        ,  0.51724138,  0.90521327,  0.48051948,  0.69230769,\n",
      "        1.        ,  0.2       ,  0.85853659,  0.82      ,  0.70680628,\n",
      "        0.89361702,  0.30769231,  0.75409836,  0.86592179,  0.77931034,\n",
      "        0.79166667,  0.5       ,  0.        ,  0.2       ,  1.        ,\n",
      "        0.57718121,  0.8       ,  0.66115702,  0.28571429,  1.        ,\n",
      "        0.        ,  0.6       ,  0.9       ,  0.66666667,  0.66666667,\n",
      "        0.75      ,  0.80357143,  0.5       ,  0.52631579,  0.74061433,\n",
      "        0.55555556,  0.        ,  0.76923077,  0.625     ,  0.57142857,\n",
      "        0.5       ,  0.5       ,  0.56989247,  0.5       ,  0.54761905,\n",
      "        0.        ,  0.45454545,  0.875     ,  0.83333333,  0.        ,\n",
      "        0.        ,  0.89385475,  0.62411348,  0.6       ,  0.66666667,\n",
      "        0.67741935,  0.80729167,  0.        ,  0.76923077,  0.        ,\n",
      "        0.        ,  0.25      ,  0.91666667]), array([ 0.        ,  0.82352941,  0.92372881,  0.48275862,  1.        ,\n",
      "        0.53448276,  0.125     ,  0.73964497,  0.        ,  0.7       ,\n",
      "        0.8       ,  0.84848485,  0.        ,  0.        ,  0.49411765,\n",
      "        0.        ,  0.69333333,  0.        ,  0.        ,  0.80130293,\n",
      "        0.75672707,  0.71465296,  0.83937824,  0.        ,  0.4       ,\n",
      "        0.        ,  0.28571429,  1.        ,  1.        ,  0.66666667,\n",
      "        0.72727273,  0.64      ,  0.57142857,  0.        ,  0.50793651,\n",
      "        0.78980892,  0.72727273,  0.68      ,  0.61746988,  0.5       ,\n",
      "        0.57668712,  0.        ,  0.61818182,  0.83783784,  0.        ,\n",
      "        0.        ,  0.42424242,  0.76923077,  0.        ,  0.73333333,\n",
      "        0.7985348 ,  0.66666667,  0.57142857,  0.26666667,  0.66666667,\n",
      "        0.5       ,  0.        ,  0.        ,  0.88215488,  0.3       ,\n",
      "        0.65396825,  0.57142857,  0.61538462,  0.8       ,  0.54285714,\n",
      "        0.        ,  0.59259259,  0.64377682,  0.        ,  0.95652174,\n",
      "        0.375     ,  1.        ,  0.75      ,  0.61538462,  0.62184874,\n",
      "        0.78688525,  0.83236994,  0.80597015,  0.        ,  0.82116788,\n",
      "        1.        ,  0.5       ,  0.77777778,  0.82882883,  0.82718219,\n",
      "        0.        ,  0.        ,  0.65814696,  0.        ,  0.33333333,\n",
      "        1.        ,  0.90909091,  0.        ,  0.8245614 ,  0.79768786,\n",
      "        0.7260274 ,  0.8       ,  1.        ,  0.36363636,  0.68571429,\n",
      "        0.37037037,  0.76666667,  0.875     ,  0.41176471,  0.        ,\n",
      "        0.68421053,  0.53333333,  0.72463768,  0.        ,  0.        ,\n",
      "        0.70588235,  1.        ,  0.66666667,  0.89655172,  0.42857143,\n",
      "        0.        ,  0.5       ,  0.        ,  0.4       ,  0.67346939,\n",
      "        0.76315789,  0.68131868,  0.41025641,  0.69565217,  0.88607595,\n",
      "        0.91735537,  0.33333333,  0.67857143,  0.        ,  0.93939394,\n",
      "        0.        ,  0.66666667,  0.5       ,  0.        ,  1.        ,\n",
      "        0.79498861,  0.5       ,  0.82893451,  0.87562189,  0.        ,\n",
      "        0.44444444,  0.        ,  1.        ,  0.66666667,  0.78873239,\n",
      "        0.75862069,  0.73513514,  0.7311828 ,  0.5       ,  0.90909091,\n",
      "        0.        ,  0.        ,  0.88888889,  0.        ,  0.        ,\n",
      "        0.        ,  0.56603774,  0.92048193,  0.58730159,  0.7826087 ,\n",
      "        0.66666667,  0.28571429,  0.87780549,  0.83248731,  0.74585635,\n",
      "        0.80769231,  0.42105263,  0.67647059,  0.87078652,  0.79298246,\n",
      "        0.83977901,  0.66666667,  0.        ,  0.18181818,  0.66666667,\n",
      "        0.62093863,  0.72727273,  0.7079646 ,  0.44444444,  0.5       ,\n",
      "        0.        ,  0.66666667,  0.9       ,  0.66666667,  0.72727273,\n",
      "        0.78947368,  0.86124402,  0.5       ,  0.51282051,  0.75347222,\n",
      "        0.71428571,  0.        ,  0.76923077,  0.76923077,  0.47058824,\n",
      "        0.5       ,  0.5       ,  0.6362545 ,  0.33333333,  0.60526316,\n",
      "        0.        ,  0.58823529,  0.8       ,  0.86538462,  0.        ,\n",
      "        0.        ,  0.91428571,  0.71836735,  0.6122449 ,  0.5       ,\n",
      "        0.76363636,  0.76732673,  0.        ,  0.86956522,  0.        ,\n",
      "        0.        ,  0.4       ,  0.93220339]), array([   0,    8,  115,   14,   48,   64,   10,  186,    1,   12,    3,\n",
      "         51,    0,    1,   36,    0,   33,    1,    0,  143, 1001,  204,\n",
      "        191,    0,    3,    0,    3,    1,    3,   15,    4,   12,    5,\n",
      "          0,   34,  482,    5,   24,  355,   18,   91,    0,   60,  176,\n",
      "          2,    2,   36,    5,    0,   31,  133,    2,    4,    6,    2,\n",
      "          1,    1,    0,  306,    8,  180,    6,    7,    9,   41,    1,\n",
      "        251,  127,    3,   95,   18,    1,    5,    7,   63,   28,   89,\n",
      "        273,    1,  263,    1,   11,    9,  175,  890,    2,    0,  179,\n",
      "          0,    4,    7,   12,    1,  362,  364,   85,    2,    1,    5,\n",
      "         15,   28,  120,  360,   28,    0,   18,    6,   33,    0,    2,\n",
      "         10,    1,    5,   14,    4,    1,    3,    0,    2,  207,   37,\n",
      "         46,   18,   12,   81,  125,    5,  133,    2,  100,    1,    2,\n",
      "          2,    1,    6,  446,    7,  508,   98,    1,    7,    2,    2,\n",
      "          1,   75,   16,  100,   48,    5,    6,    2,    0,  542,    0,\n",
      "          2,    0,   29,  211,   77,   13,    1,    5,  205,  100,  191,\n",
      "         47,   13,   61,  179,  290,   96,    2,    1,    5,    1,  149,\n",
      "         20,  121,    7,    1,    0,    5,   10,   12,    6,   20,  112,\n",
      "          6,   19,  586,   18,    0,  117,    8,    7,    2,    2,  930,\n",
      "          2,   42,    1,   11,   16,   54,    0,    0,  179,  141,   25,\n",
      "          6,   62,  192,    0,   13,    1,    0,    4,  180]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_train,\"true_train\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_dev,\"true_dev\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
