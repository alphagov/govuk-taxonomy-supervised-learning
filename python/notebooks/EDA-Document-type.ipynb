{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document type distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare distribution of documents by type, and over time, in the following document populations:\n",
    "- untagged \n",
    "- labelled\n",
    "- filtered\n",
    "- tagged to level 1 only\n",
    "- tagged to level2 or lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import matplotlib as mpl\n",
    "import json\n",
    "%matplotlib inline\n",
    "inline_rc = dict(mpl.rcParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in untagged content to describe content with no taxons\n",
    "untagged = pd.read_csv('../../data/untagged_content.csv')\n",
    "labelled = pd.read_csv('../../data/labelled.csv')\n",
    "filtered = pd.read_csv('../../data/filtered.csv')\n",
    "taxons = pd.read_csv('../../data/clean_taxons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency of documents in each category of document type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untagged.groupby('document_type').size().sort_values(ascending=True).plot(kind = 'barh', figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled.groupby('document_type').size().sort_values(ascending=True).plot(kind = 'barh', figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.groupby('document_type').size().sort_values(ascending=True).plot(kind = 'barh', figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations/Conclusions\n",
    "The untagged content appears to have a different distribution of document type compared to the tagged content, both before and after filtering the World/Corporate categories and deduplication. \n",
    "\n",
    "For example, relatively few guidance , policy paper and research documents are untagged. World_news_story, foi releases are over-represented in untagged data compared to tagged data.\n",
    "\n",
    "This is likely to result in a drop inaccuracy when moving from modelling data to predicting for untagged data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series analyses of content type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the overall frequency of publications over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#untagged['first_published_at'].resample('Y').count().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_singlelabel = filtered.drop_duplicates('content_id').reset_index(drop=True)\n",
    "print(f_singlelabel['first_published_at'][f_singlelabel['first_published_at'].str.contains('0001-01-01', na=False)])\n",
    "\n",
    "f_singlelabel.drop(f_singlelabel.index[[58843]], inplace=True)\n",
    "f_singlelabel['first_published_at'] = pd.to_datetime(f_singlelabel['first_published_at'])\n",
    "f_singlelabel.index = f_singlelabel['first_published_at'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_singlelabel = labelled.drop_duplicates('content_id').reset_index(drop=True)\n",
    "\n",
    "\n",
    "l_singlelabel['first_published_at'] = l_singlelabel['first_published_at'].str.replace('0001-01-01', '2001-01-01')\n",
    "\n",
    "print(l_singlelabel['first_published_at'][l_singlelabel['first_published_at'].str.contains('0001-01-01', na=False)])\n",
    "\n",
    "l_singlelabel.drop(l_singlelabel.index[[58843]], inplace=True)\n",
    "l_singlelabel['first_published_at'] = pd.to_datetime(l_singlelabel['first_published_at'])\n",
    "l_singlelabel.index = l_singlelabel['first_published_at'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus: since 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Untagged data')\n",
    "unlab = untagged['first_published_at'].resample('Y').count().plot()\n",
    "unlab.set_xlim(pd.Timestamp('2000-12-31'), pd.Timestamp('2017-12-31'))\n",
    "unlab.set_ylim([0, 30000])\n",
    "\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "lab=l_singlelabel['first_published_at'].resample('Y').count().plot()\n",
    "lab.set_xlim(pd.Timestamp('2000-12-31'), pd.Timestamp('2017-12-31'))\n",
    "plt.title('Labelled data')\n",
    "plt.ylabel('Count')\n",
    "lab.set_ylim([0, 30000])\n",
    "lab.axes.get_xaxis().set_ticklabels([])\n",
    "lab.set_xlabel('')\n",
    "\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "lab=f_singlelabel['first_published_at'].resample('Y').count().plot()\n",
    "lab.set_xlim(pd.Timestamp('2000-12-31'), pd.Timestamp('2017-12-31'))\n",
    "plt.title('Filtered data')\n",
    "plt.ylabel('Count')\n",
    "lab.set_ylim([0, 30000])\n",
    "lab.axes.get_xaxis().set_ticklabels([])\n",
    "lab.set_xlabel('')\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the publication frequency over time by document type?\n",
    "### Unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = untagged.groupby(['document_type', pd.Grouper(freq='Y')])['first_published_at'].count()\n",
    "count_by_year = grouped.unstack('document_type', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are too many document types to plot on one chart so select the types with highest maximum\n",
    "top_count = count_by_year.loc[:,count_by_year.max() > 500]\n",
    "ax = top_count.plot()\n",
    "ax.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = grouped.unstack('document_type', fill_value=0).plot()\n",
    "#ax.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "#ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to compare distribution of document types over time with the labelled data, this needs to be relative not absolute. So change into percent of documents published that year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = count_by_year.stack().reset_index()\n",
    "df.columns = ['date', 'document_type', 'percent']\n",
    "bydoctype_year = df.groupby(['date', 'document_type']).agg({'percent': 'sum'})\n",
    "# Change: groupby state_office and divide by sum\n",
    "bydoctype_pcts = bydoctype_year.groupby(level=0).apply(lambda x:\n",
    "                                                 100 * x / float(x.sum())).unstack('document_type', fill_value=0)\n",
    "\n",
    "bydoctype_pcts.columns = bydoctype_pcts.columns.droplevel(0)\n",
    "bydoctype_pcts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_pct = bydoctype_pcts.loc[:,bydoctype_pcts.max() > 15]\n",
    "print(top_pct.columns.values)\n",
    "\n",
    "top_pct = bydoctype_pcts[['correspondence', 'decision'\n",
    " , 'fatality_notice',  'foi_release',\n",
    "  'guidance', 'independent_report', 'international_treaty', 'news_story', 'research', 'world_news_story']]\n",
    "\n",
    "\n",
    "# ax = top_pct.plot(kind='area', stacked=True)\n",
    "\n",
    "# ax.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "# plt.title(\"Labelled data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_grouped = l_singlelabel.groupby(['document_type', pd.Grouper(freq='Y')])['first_published_at'].count()\n",
    "l_count_by_year = l_grouped.unstack('document_type', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are too many document types to plot on one chart so select the types with highest maximum\n",
    "l_top_count = l_count_by_year.loc[:,l_count_by_year.max() > 1000]\n",
    "ax = l_top_count.plot()\n",
    "ax.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = l_count_by_year.stack().reset_index()\n",
    "df_lab.columns = ['date', 'document_type', 'percent']\n",
    "l_bydoctype_year = df_lab.groupby(['date', 'document_type']).agg({'percent': 'sum'})\n",
    "# Change: groupby state_office and divide by sum\n",
    "l_bydoctype_pcts = l_bydoctype_year.groupby(level=0).apply(lambda x:\n",
    "                                                 100 * x / float(x.sum())).unstack('document_type', fill_value=0)\n",
    "\n",
    "l_bydoctype_pcts.columns = l_bydoctype_pcts.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_top_pct = l_bydoctype_pcts[['correspondence', 'decision'\n",
    " , 'fatality_notice',  'foi_release',\n",
    "  'guidance', 'independent_report', 'international_treaty', 'news_story', 'research', 'world_news_story']]\n",
    "\n",
    "# ax = utop_pct.plot(kind='area', stacked=True)\n",
    "# plt.title('Unlabelled')\n",
    "# ax.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_grouped = f_singlelabel.groupby(['document_type', pd.Grouper(freq='Y')])['first_published_at'].count()\n",
    "f_count_by_year = f_grouped.unstack('document_type', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are too many document types to plot on one chart so select the types with highest maximum\n",
    "f_top_count = f_count_by_year.loc[:,f_count_by_year.max() > 1000]\n",
    "ax = f_top_count.plot()\n",
    "ax.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = f_count_by_year.stack().reset_index()\n",
    "df_lab.columns = ['date', 'document_type', 'percent']\n",
    "f_bydoctype_year = df_lab.groupby(['date', 'document_type']).agg({'percent': 'sum'})\n",
    "# Change: groupby state_office and divide by sum\n",
    "f_bydoctype_pcts = f_bydoctype_year.groupby(level=0).apply(lambda x:\n",
    "                                                 100 * x / float(x.sum())).unstack('document_type', fill_value=0)\n",
    "\n",
    "f_bydoctype_pcts.columns = f_bydoctype_pcts.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_top_pct = f_bydoctype_pcts[['correspondence', 'decision'\n",
    " , 'fatality_notice',  'foi_release',\n",
    "  'guidance', 'independent_report', 'international_treaty', 'news_story', 'research', 'world_news_story']]\n",
    "\n",
    "# ax = utop_pct.plot(kind='area', stacked=True)\n",
    "# plt.title('Unlabelled')\n",
    "# ax.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare document type distribution over time beween cuntageed, labelled, filtered\n",
    "ut = top_pct.plot(kind='area', stacked=True)\n",
    "ut.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "ut.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Untagged\")\n",
    "\n",
    "lab = l_top_pct.plot(kind='area', stacked=True)\n",
    "lab.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "lab.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Labelled\")\n",
    "\n",
    "filt = f_top_pct.plot(kind='area', stacked=True)\n",
    "filt.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "filt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagged to level1 only compared to level2 or lower in LABELLED data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This section could be moved to EDA-taxons.ipynb__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only keep rows where level1/level2 combination is unique\n",
    "level2_dedup = labelled.drop_duplicates(subset = ['content_id', 'level1taxon', 'level2taxon']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(level2_dedup['first_published_at'][level2_dedup['first_published_at'].str.contains('0001-01-01', na=False)])\n",
    "level2_dedup['first_published_at'] = level2_dedup['first_published_at'].str.replace('0001-01-01', '2001-01-01')\n",
    "\n",
    "print(\"There were {} content item/taxons before removing duplicates\".format(labelled.shape[0]))\n",
    "print(\"There were {} content items, unique level2 taxon pairs after removing duplicates by content_id, level1taxon and level2taxon\".format(level2_dedup.shape[0]))\n",
    "\n",
    "#Identify and drop rows where level2 is missing\n",
    "mask= pd.notnull(level2_dedup['level2taxon'])\n",
    "level1_tagged = level2_dedup[~mask].copy()\n",
    "print(\"There are {} content items only tagged to level1\".format(level1_tagged.shape[0]))\n",
    "level2_tagged = level2_dedup[mask].copy()\n",
    "print(\"There are {} content items tagged to level2 or lower\".format(level2_tagged.shape[0]))\n",
    "\n",
    "print(\"{} + {} = {}\".format(level1_tagged.shape[0], level2_tagged.shape[0], (level1_tagged.shape[0] + level2_tagged.shape[0])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#level1\n",
    "level1_tagged['first_published_at'] = pd.to_datetime(level1_tagged['first_published_at'])\n",
    "level1_tagged.index = level1_tagged['first_published_at']\n",
    "\n",
    "\n",
    "l1_grouped = level1_tagged.groupby(['document_type', pd.Grouper(freq='Y')])['first_published_at'].count()\n",
    "l1_count_by_year = l1_grouped.unstack('document_type', fill_value=0)\n",
    "#There are too many document types to plot on one chart so select the types with highest maximum\n",
    "l1_top_count = l1_count_by_year.loc[:,l1_count_by_year.max() > 300]\n",
    "\n",
    "ax = l1_top_count.plot()\n",
    "ax.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l1 = l1_count_by_year.stack().reset_index()\n",
    "df_l1.columns = ['date', 'document_type', 'percent']\n",
    "l1_bydoctype_year = df_l1.groupby(['date', 'document_type']).agg({'percent': 'sum'})\n",
    "# Change: groupby state_office and divide by sum\n",
    "l1_bydoctype_pcts = l1_bydoctype_year.groupby(level=0).apply(lambda x:\n",
    "                                                 100 * x / float(x.sum())).unstack('document_type', fill_value=0)\n",
    "\n",
    "\n",
    "l1_bydoctype_pcts.columns = l1_bydoctype_pcts.columns.droplevel(0)\n",
    "l1_top_pct = l1_bydoctype_pcts.loc[:,l1_bydoctype_pcts.max() > 20]\n",
    "l1_top_pct.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#level2\n",
    "level2_tagged['first_published_at'] = pd.to_datetime(level2_tagged['first_published_at'])\n",
    "level2_tagged.index = level2_tagged['first_published_at']\n",
    "\n",
    "\n",
    "l2_grouped = level2_tagged.groupby(['document_type', pd.Grouper(freq='Y')])['first_published_at'].count()\n",
    "l2_count_by_year = l2_grouped.unstack('document_type', fill_value=0)\n",
    "#There are too many document types to plot on one chart so select the types with highest maximum\n",
    "l2_top_count = l2_count_by_year.loc[:,l2_count_by_year.max() > 1400]\n",
    "\n",
    "#Graph (absolute numbers)\n",
    "ax = l2_top_count.plot()\n",
    "ax.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relative\n",
    "df_l2 = l2_count_by_year.stack().reset_index()\n",
    "df_l2.columns = ['date', 'document_type', 'percent']\n",
    "l2_bydoctype_year = df_l2.groupby(['date', 'document_type']).agg({'percent': 'sum'})\n",
    "# Change: groupby state_office and divide by sum\n",
    "l2_bydoctype_pcts = l2_bydoctype_year.groupby(level=0).apply(lambda x:\n",
    "                                                 100 * x / float(x.sum())).unstack('document_type', fill_value=0)\n",
    "\n",
    "l2_bydoctype_pcts.columns = l2_bydoctype_pcts.columns.droplevel(0)\n",
    "\n",
    "#To compare with labelled level1\n",
    "l2_top_pct = l2_bydoctype_pcts[['decision', 'fatality_notice', 'guidance', 'independent_report',\n",
    "       'international_treaty', 'national_statistics', 'notice',\n",
    "       'policy_paper', 'research', 'statutory_guidance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare document type distribution over time beween content items tagged to level1 only and those tagged to level2 or lower\n",
    "lev1 = l1_top_pct.plot(kind='area', stacked=True)\n",
    "lev1.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "lev1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Percent level1\")\n",
    "\n",
    "lev2 = l2_top_pct.plot(kind='area', stacked=True)\n",
    "lev2.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "lev2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Percent level2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare all populations on same 10 doc types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To compare with labelled level1\n",
    "l1_top_pct = l1_bydoctype_pcts[['correspondence', 'decision'\n",
    " , 'fatality_notice',  'foi_release',\n",
    "  'guidance', 'independent_report', 'international_treaty', 'news_story', 'research', 'world_news_story']]\n",
    "\n",
    "l2_top_pct = l2_bydoctype_pcts[['correspondence', 'decision'\n",
    " , 'fatality_notice',  'foi_release',\n",
    "  'guidance', 'independent_report', 'international_treaty', 'news_story', 'research', 'world_news_story']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare document type distribution over time beween cuntageed, labelled, filtered\n",
    "ut = top_pct.plot(kind='area', stacked=True)\n",
    "ut.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "ut.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Untagged\")\n",
    "\n",
    "lab = l_top_pct.plot(kind='area', stacked=True)\n",
    "lab.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "lab.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Labelled\")\n",
    "\n",
    "filt = f_top_pct.plot(kind='area', stacked=True)\n",
    "filt.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "filt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Filtered\")\n",
    "\n",
    "#Compare document type distribution over time beween content items tagged to level1 only and those tagged to level2 or lower\n",
    "lev1 = l1_top_pct.plot(kind='area', stacked=True)\n",
    "lev1.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "lev1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Percent level1\")\n",
    "\n",
    "lev2 = l2_top_pct.plot(kind='area', stacked=True)\n",
    "lev2.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "lev2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Percent level2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations/conclusions\n",
    "- Document distirbution changes over time with news stories decreasing in relative frequency\n",
    "- There are substantial differences in document type composition between the untagged data and the filtered/labelled data particularly:\n",
    "    - FOI releases more represented in untagged\n",
    "    - guidance less represented in untagged\n",
    "    - World news, especially recently, more represented in untagged\n",
    "    - Fatality notices, have historically been less represented in untagged\n",
    "- About half of content fell into these 10 categories in 2016\n",
    "- ONly 20% of untagged content fell into these categories in 2017 (Are we waiting for an end of year publicaiton flurry?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document type groupings\n",
    "These groupings have been devised by need and could be used to supplement this analysis or interpretation\n",
    "https://gov-uk.atlassian.net/wiki/spaces/GFED/pages/187564388/Grouping+document+types+by+need\n",
    "- __News and announcements__\n",
    "    - Updates & alerts\n",
    "    - News (promotions)\n",
    "    - Marketing\n",
    "    - Speeches\n",
    "- __Guidance__\n",
    "   - Guidance\n",
    "   - Contacts\n",
    "- __Service__\n",
    "   - Transactions\n",
    "- __Outcomes__\n",
    "   - Reports\n",
    "   - Decisions\n",
    "- __Transparency__\n",
    "   - Engagement activities\n",
    "   - Data\n",
    "- __Organising entities__\n",
    "   - Organising entities\n",
    "   - Support\n",
    "- __Out of scope__\n",
    "   - Navigation pages\n",
    "   - Lists\n",
    "- __Stand alone__\n",
    "   - Corporate info\n",
    "   - Service manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Consider grouping the individual doc types if further analyses required. \n",
    "# #This would be performed in the cleaning scripts, as below:\n",
    "# def generate_doctype_gp(df):\n",
    "#     df['doc_type_gp'] = 'other'\n",
    "#     #NEWS&ANNOUNCEMENTS\n",
    "#     #Update&alerts\n",
    "#     df.loc[df['document_type'] == 'vehicle_recalls_and_faults_alert', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'fatality_notice', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'medical_safety_alert', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'drug_safety_update', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'statistics_announcement', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'staff_update', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'national_statistics_announcement', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'press_release', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'official_statistics_announcement', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     #Mews(promotions)\n",
    "#     df.loc[df['document_type'] == 'news_article', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'news_story', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'world_location_news_article', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'world_news_story', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'authored_article', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     #Marketing\n",
    "#     df.loc[df['document_type'] == 'promotional', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'coming_soon', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     #Speeches\n",
    "#     df.loc[df['document_type'] == 'oral_statement', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'speech', 'doc_type_gp'] = 'news_and_announcements'\n",
    "#     df.loc[df['document_type'] == 'written_statement', 'doc_type_gp'] = 'news_and_announcements'\n",
    "\n",
    "\n",
    "\n",
    "#     #Guidance\n",
    "#     #guidance\n",
    "#     df.loc[df['document_type'] == 'travel_advice', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'guide', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'calendar', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'answer', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'html_publication', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'detailed_guide', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'statuatory_guidance', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'specialist_document', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'manual', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'manual_section', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'hmrc_manual', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'hmrc_manual_section', 'doc_type_gp'] = 'guidance'\n",
    "#     df.loc[df['document_type'] == 'topical_event_about_page', 'doc_type_gp'] = 'guidance'\n",
    "#     #contacts\n",
    "#     df.loc[df['document_type'] == 'contact', 'doc_type_gp'] = 'guidance'\n",
    "    \n",
    "    \n",
    "#     #Service\n",
    "#     #Transactions\n",
    "#     df.loc[df['document_type'] == 'transaction', 'doc_type_gp'] = 'service'\n",
    "#     df.loc[df['document_type'] == 'local_transaction', 'doc_type_gp'] = 'service'\n",
    "#     df.loc[df['document_type'] == 'completed_transaction', 'doc_type_gp'] = 'service'\n",
    "#     df.loc[df['document_type'] == 'form', 'doc_type_gp'] = 'service'\n",
    "#     df.loc[df['document_type'] == 'calculator', 'doc_type_gp'] = 'service'\n",
    "#     df.loc[df['document_type'] == 'smart_answer', 'doc_type_gp'] = 'service'\n",
    "#     df.loc[df['document_type'] == 'simple_smart_answer', 'doc_type_gp'] = 'service'\n",
    "#     df.loc[df['document_type'] == 'place', 'doc_type_gp'] = 'service'\n",
    "\n",
    "    \n",
    "#     #Outcomes\n",
    "#     #Reports\n",
    "#     df.loc[df['document_type'] == 'aaib_report', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'maib_report', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'raib_report', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'financial_release', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'service_standard_report', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'regulation', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'independent_report', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'consultation_outcome', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'impact_assessment', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'procurement', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'research', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'case_study', 'doc_type_gp'] = 'outcomes'\n",
    "#     #Decisions\n",
    "#     df.loc[df['document_type'] == 'decision', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'employment_tribunal_decision', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'tax_tribunal_decision', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'government_reponse', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'utaac_decision', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'dfid_research_output', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'asylum_support_decision', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'employment_appeal_tribunal_decision', 'doc_type_gp'] = 'outcomes'\n",
    "#     df.loc[df['document_type'] == 'international_treaty', 'doc_type_gp'] = 'outcomes'\n",
    "\n",
    "    \n",
    "#     #Transparency\n",
    "#     #Engagement Activities\n",
    "#     df.loc[df['document_type'] == ' cma_case', 'doc_type_gp'] = 'transparency'\n",
    "#     df.loc[df['document_type'] == 'open_consultation', 'doc_type_gp'] = 'transparency'\n",
    "#     df.loc[df['document_type'] == 'closed_consultation', 'doc_type_gp'] = 'transparency'\n",
    "#     df.loc[df['document_type'] == 'licence', 'doc_type_gp'] = 'transparency'\n",
    "#     df.loc[df['document_type'] == 'notice', 'doc_type_gp'] = 'transparency'\n",
    "#     df.loc[df['document_type'] == 'consultation', 'doc_type_gp'] = 'transparency'\n",
    "#     #Data\n",
    "#     df.loc[df['document_type'] == 'official_statistics', 'doc_type_gp'] = 'transparency'\n",
    "#     df.loc[df['document_type'] == 'statistics', 'doc_type_gp'] = 'transparency'\n",
    "#     df.loc[df['document_type'] == 'national_statistics', 'doc_type_gp'] = 'transparency'\n",
    "#     df.loc[df['document_type'] == 'foi_release', 'doc_type_gp'] = 'transparency'\n",
    "#     df.loc[df['document_type'] == 'transparency', 'doc_type_gp'] = 'transparency'\n",
    "#     df.loc[df['document_type'] == 'correspondence', 'doc_type_gp'] = 'transparency'\n",
    "#     df.loc[df['document_type'] == 'need', 'doc_type_gp'] = 'transparency'\n",
    "    \n",
    "   \n",
    "#     #organising entities\n",
    "#     #organising entities\n",
    "#     df.loc[df['document_type'] == 'working_group', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'organisation', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'person', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'worldwide_organisation', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'world_location', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'topical_event', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'policy_area', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'field_of_operation', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'ministerial_role', 'doc_type_gp'] = 'org_entities'\n",
    "#     #support\n",
    "#     df.loc[df['document_type'] == 'international_development_fund', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'countryside_stewardship_grant', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'business_support', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'esi_fund', 'doc_type_gp'] = 'org_entities'\n",
    "#     df.loc[df['document_type'] == 'business_finance_support_scheme', 'doc_type_gp'] = 'org_entities'\n",
    "\n",
    "\n",
    "    \n",
    "#     #Out of scope\n",
    "#     #Nav pages (thinks these were removed by devs)\n",
    "#     df.loc[df['document_type'] == 'finder_email_signup', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'mainstream_browse_page', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'topic', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'take_part', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'homepage', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'licence_finder', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'search', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'taxon ', 'doc_type_gp'] = 'oo_scope'\n",
    "#     #Lists\n",
    "#     df.loc[df['document_type'] == 'travel_advice_index', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'document_collection', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'business_support_finder', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'finder', 'doc_type_gp'] = 'oo_scope'\n",
    "#     #Ways to deliver info\n",
    "#     df.loc[df['document_type'] == 'map', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'video', 'doc_type_gp'] = 'oo_scope'\n",
    "#     df.loc[df['document_type'] == 'email_alert_signup', 'doc_type_gp'] = 'oo_scope'\n",
    "    \n",
    "\n",
    "#     #Standalone\n",
    "#     #Corporate info\n",
    "#     df.loc[df['document_type'] == 'about', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'about_our_services', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'personal_information_charter', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'equality_and_diversity', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'our_governance', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'services_and_information', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'our_energy_use', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'corporate_report', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'social_media_use', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'access_and_opening', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'membership', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'publication_scheme', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'media_enquiries', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'complaints_procedure', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'help_page', 'doc_type_gp'] = 'standalone'\n",
    "#     #Service manual\n",
    "#     df.loc[df['document_type'] == 'service_manual_homepage', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'service_manual_service_toolkit', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'service_manual_service_standard', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'service_manual_guide', 'doc_type_gp'] = 'standalone'\n",
    "#     df.loc[df['document_type'] == 'service_manual_topic', 'doc_type_gp'] = 'standalone'\n",
    "   \n",
    "\n",
    "    \n",
    "#     return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions not working and already spent a while cut-and-pasting so...\n",
    "# def recode_doctype_gp(df, document_type, doctype_gp):\n",
    "#     df.loc[df['document_type'] == 'document_type', 'doc_type_gp'] = 'doctype_gp'\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "# def generate_doctype_gp_test(df):\n",
    "#     df['doctype_gp'] = df['document_type']\n",
    "    \n",
    "#     df = recode_doctype_gp(df, 'fatality_notice', 'news_and_announcements')\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untagged = generate_doctype_gp(untagged).copy()\n",
    "# labelled = generate_doctype_gp(l_singlelabel).copy()\n",
    "# filtered = generate_doctype_gp(f_singlelabel).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = untagged.groupby(['doc_type_gp', pd.Grouper(freq='Y')])['first_published_at'].count()\n",
    "count_by_year = grouped.unstack('doc_type_gp', fill_value=0)\n",
    "\n",
    "l_grouped = labelled.groupby(['doc_type_gp', pd.Grouper(freq='Y')])['first_published_at'].count()\n",
    "l_count_by_year = l_grouped.unstack('doc_type_gp', fill_value=0)\n",
    "\n",
    "f_grouped = filtered.groupby(['doc_type_gp', pd.Grouper(freq='Y')])['first_published_at'].count()\n",
    "f_count_by_year = f_grouped.unstack('doc_type_gp', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = count_by_year.plot()\n",
    "ax.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Untagged\")\n",
    "\n",
    "lab = l_count_by_year.plot()\n",
    "lab.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "lab.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Labelled\")\n",
    "\n",
    "filt = f_count_by_year.plot()\n",
    "filt.set_xlim(pd.Timestamp('2009-12-31'), pd.Timestamp('2017-12-31'))\n",
    "filt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict(zip(labelled.document_type, labelled.doc_type_gp,))\n",
    "y = dict(zip(untagged.document_type, untagged.doc_type_gp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_dicts(x, y):\n",
    "    \"\"\"Given two dicts, merge them into a new dict as a shallow copy.\"\"\"\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_doctype_gp = merge_two_dicts(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lookup_doctype_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled[\"test\"] = labelled[\"document_type\"].map(lookup_doctype_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../../data/document_type_gp_lookup.json', 'w') as fp:\n",
    "    json.dump(lookup_doctype_gp, fp)"
   ]
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "tax_SL",
   "language": "python",
   "name": "tax_sl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
